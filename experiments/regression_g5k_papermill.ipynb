{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#results_estimation=[\"variable-results/q5-20230513114908\"]\n",
    "results_estimation=[\"search-results/q5-20230604063557\"]\n",
    "results_estimation=[\"search-results/query-20230607203251\"]\n",
    "#results_estimation=[\"variable-results/q11-final-20230423060007\", \"variable-results/q11-final-20230424142915\"]\n",
    "#results_estimation=[\"variable-results/q8-final-20230422200802\"]\n",
    "kind=False\n",
    "g5k=True\n",
    "# infra\n",
    "job_managers_qty = 8\n",
    "kafka_qty = 8\n",
    "kafka_partitions=32\n",
    "kafka_replicas=8\n",
    "kafka_node_selector=\"kafka\"\n",
    "reset_kafka_data = True\n",
    "model_type = \"log\"\n",
    "flink_limit_sources = True\n",
    "\n",
    "cpu= 16\n",
    "task_slots_per_task_manager = 16\n",
    "task_managers_qty = 32\n",
    "ratio_tm = 80 / 128\n",
    "\n",
    "source_parallelism = 32\n",
    "source_capacity = 150000\n",
    "memory_range = [65536] \n",
    "\n",
    "datagen_configuration = {\n",
    "    \"parallelism\": 32,\n",
    "    \"cpu\": 8,\n",
    "    \"memory\" : 16384,\n",
    "    \"task_managers_qty\": 8,\n",
    "    \"task_slots\": 8,\n",
    "    \"timeout\": 600,\n",
    "    \"notebook\": \"/xp_datagen\"\n",
    "}\n",
    "throughput_ratios = [1., 1.2, 1.5]\n",
    "\n",
    "results_path = \"regression-results/\"\n",
    "\n",
    "notebook = \"/xp_intro_q5_kafka\"\n",
    "filter_data = \"\"\n",
    "warmup = 120\n",
    "sensitivity = 0.01\n",
    "ratio = 1\n",
    "\n",
    "xp_name = \"query\"\n",
    "task_slots_limits = []\n",
    "timeout = 1800\n",
    "throughputs = [2500000]\n",
    "\n",
    "compute_reg = 15\n",
    "\n",
    "ratio_overhead_throughput = 1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import sys\n",
    "%run ../common/scripts.ipynb\n",
    "if \"../streambed\" not in sys.path:\n",
    "    sys.path.append(\"../streambed\")\n",
    "import streambed\n",
    "streambed.setup_logging(default_path=\"./logging.yaml\", default_level=logging.WARN)\n",
    "logger = logging.getLogger('streambed')\n",
    "if kind:\n",
    "    streambed.init_kind()\n",
    "if g5k:\n",
    "    streambed.init_g5k()\n",
    "\n",
    "logging.info(\"Execute notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = streambed.InfrastructureRegression()\n",
    "\n",
    "for result_file in results_estimation:\n",
    "    reg.load(\"{}.csv\".format(result_file))\n",
    "    reg.load_details(\"{}-details.yaml\".format(result_file))\n",
    "reg.filter_data(filter_data)\n",
    "\n",
    "reg.data[[\"used_task_slots\", \"memory\", \"observed_source_rate\"]]\n",
    "\n",
    "\n",
    "reg.heatmap()\n",
    "\n",
    "sqrt_regression = make_pipeline(FunctionTransformer(np.sqrt, validate=True), LinearRegression())\n",
    "_, score = reg.generic_model(\"sqrt\", sqrt_regression)\n",
    "throughput = reg.predict(\"sqrt\", task_managers_qty*cpu, 65536)\n",
    "print(\"Sqrt: {} - {}\".format(score, throughput))\n",
    "logarithmic_regression = make_pipeline(FunctionTransformer(np.log1p, validate=True), LinearRegression())\n",
    "_, score = reg.generic_model(\"log\", logarithmic_regression)\n",
    "throughput = reg.predict(\"log\", task_managers_qty*cpu, 65536)\n",
    "print(\"Log: {} - {}\".format(score, throughput))\n",
    "\n",
    "linear_regression = make_pipeline(PolynomialFeatures(degree=1), LinearRegression())\n",
    "_, score = reg.generic_model(\"linear\", linear_regression)\n",
    "throughput = reg.predict(\"linear\", task_managers_qty*cpu, 65536)\n",
    "print(\"Linear: {} - {}\".format(score, throughput))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    \"linear\": make_pipeline(PolynomialFeatures(degree=1),  LinearRegression()),\n",
    "    \"log\": make_pipeline(FunctionTransformer(np.log1p, validate=True), LinearRegression()),\n",
    "    \"sqrt\": make_pipeline(FunctionTransformer(np.sqrt, validate=True), LinearRegression())\n",
    "}\n",
    "\n",
    "for pipeline in pipelines:\n",
    "    print(\"******** {} *******\".format(pipeline))\n",
    "    (models, scores) = reg.generic_models(pipelines[pipeline],5, 20)\n",
    "    low_score = None\n",
    "    low_index = None\n",
    "    for i in range(len(models)): \n",
    "        if (low_score is None) or (low_score < scores[i]):\n",
    "            low_index = i\n",
    "            low_score = scores[i]\n",
    "            reg.set_model(pipeline, models[i])\n",
    "        display()\n",
    "        logger.debug(\"{} {} {}\".format(i, scores[i], reg.compute_x(pipeline, throughputs[0], range(10,1000), [65536])))\n",
    "    print(\"Selected: {} - {}\".format(low_index, scores[low_index], reg.compute_x(\"sqrt\", throughputs[0], range(10,1000), [65536])))\n",
    "    logger.info(\"Selected: {} - {}\".format(low_index, scores[low_index], reg.compute_x(\"sqrt\", throughputs[0], range(10,1000), [65536])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "limit_ts_train = reg.data[\"used_task_slots\"].max() // 2\n",
    "data = reg.data[[\"used_task_slots\", \"memory\", \"observed_source_rate\"]]        \n",
    "train = data.query(\"(used_task_slots < {})\".format(limit_ts_train))\n",
    "test = data.query(\"(used_task_slots >= {})\".format(limit_ts_train))\n",
    "X_train = train.iloc[:, :-1].values\n",
    "y_train = train.iloc[:, -1].values      \n",
    "X_test = test.iloc[:, :-1].values\n",
    "y_test = test.iloc[:, -1].values    \n",
    "for name in reg.models:\n",
    "    print(name)\n",
    "    model = clone(reg.models[name])\n",
    "    loo = LeaveOneOut()\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=loo, scoring='neg_root_mean_squared_error')\n",
    "    display(np.mean(scores))        \n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    # Assess the trained model's performance on the validation set\n",
    "    y_val_pred = model.predict(X_train)\n",
    "    trained_rmse = np.sqrt(mean_squared_error(y_train, y_val_pred))\n",
    "    print(f\"Trained RMSE: {trained_rmse}\")\n",
    "\n",
    "    # Finally, you can evaluate the final model's performance on the test set.\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    final_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    print(f\"Final RMSE: {final_rmse}\")  \n",
    "    logger.info(f\"Model {name} - Trained RMSE: {trained_rmse} - Final RMSE: {final_rmse}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = []\n",
    "X2 = []\n",
    "y = []\n",
    "mo = []\n",
    "for model in reg.models:\n",
    "\n",
    "\n",
    "    for i in range(1,task_managers_qty):\n",
    "        for m in memory_range:\n",
    "            t = cpu*i\n",
    "            X1.append(t)\n",
    "            X2.append(m)\n",
    "            val = reg.predict(model, t,m)[0]\n",
    "            y.append(val)\n",
    "            mo.append(model)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ts': np.array(X1),\n",
    "    'mem': np.array(X2),\n",
    "    'tp' : np.array(y),\n",
    "    'model' : mo\n",
    "})\n",
    "sns.relplot(data=df, x=\"ts\", y=\"tp\", hue=\"mem\", col=\"model\")\n",
    "reg.get_parallelism_throughput(throughputs[0], memory_range[0], source_capacity, model_name=model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "task_parallelism, task_slots, needed_sources = reg.get_parallelism_throughput(throughputs[0], memory_range[0], source_capacity, model_name=model_type)\n",
    "task_parallelism, task_slots, needed_sources\n",
    "if not flink_limit_sources:\n",
    "    needed_sources = kafka_partitions\n",
    "tm_qty = math.ceil((task_slots + needed_sources)/ task_slots_per_task_manager)\n",
    "actual_needed_task_managers_qty = math.ceil(tm_qty / ratio_tm)\n",
    "logger.info(\"Needed: {} ({} + {}) - needed TM : {} - needed TM with load: {}\".format( task_slots + needed_sources, needed_sources, task_slots, tm_qty, actual_needed_task_managers_qty ))\n",
    "\"Needed: {} ({} + {}) - needed TM : {} - needed not fully loaded TM : {}\".format( task_slots + needed_sources, needed_sources, task_slots, tm_qty, actual_needed_task_managers_qty )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=Reset_Kafka\n",
    "init_label_nodes(jobmanagers_qty=job_managers_qty, kafka_qty=kafka_qty)\n",
    "if reset_kafka_data:\n",
    "    #papermill_description=Initialize libraries\n",
    " \n",
    "    address = \"127-0-0-1\"\n",
    "    port=30081\n",
    "\n",
    "    !kubectl delete -n kafka kafka/my-cluster\n",
    "    sleep(10)\n",
    "    if kafka_qty > 0:\n",
    "        #run_command(\"kubectl create -f ./kafka.yaml\", shell=False)\n",
    "        streambed.deploy_kafka(kafka_partitions, kafka_replicas, node_selector=kafka_node_selector, antiaffinity=g5k, retention_duration=5) # set to 5 minutes retention\n",
    "        run_command(\"kubectl wait kafka/my-cluster --for=condition=Ready --timeout=300s -n kafka\", shell=False)\n",
    "        # Kafka UI\n",
    "        run_command(\"helm install -f values-kowl.yaml -n kafka kowl cloudhut/kowl\", shell=False)\n",
    "        #(ip_url, dns_url) = get_service_public_address(\"kafka\", \"manager\", \"kowl\", 80)\n",
    "        (manager_node, jobmanager_node, taskmanager_node) = get_label_nodes()\n",
    "        print(\"Kafka Kowl: {} - Ingress: {}\".format(manager_node, \"http://kowl.{}.sslip.io:{}\".format(address,port)))    \n",
    "        !kubectl apply -f ./kafka-bridge.yaml\n",
    "        !kubectl apply -f ./kafka-bridge-service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(throughput_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_xp=[]\n",
    "for memory in memory_range:\n",
    "    for throughput in throughputs:\n",
    "        task_parallelism, task_slots, needed_sources = reg.get_parallelism_throughput(throughput * ratio_overhead_throughput, memory, source_capacity, model_name=model_type)\n",
    "        if not flink_limit_sources:\n",
    "            needed_sources = kafka_partitions     \n",
    "        task_parallelism, task_slots, needed_sources\n",
    "        tm_qty = math.ceil((task_slots + needed_sources)/ task_slots_per_task_manager)\n",
    "        actual_needed_task_managers_qty = math.ceil(tm_qty / ratio_tm)\n",
    "        logger.info(\"Needed: {} ({} + {}) - needed TM : {} - needed TM with load: {}\".format( task_slots + needed_sources, needed_sources, task_slots, tm_qty, actual_needed_task_managers_qty ))\n",
    "        display(\"Needed: {} ({} + {}) - needed TM : {} - needed not fully loaded TM : {}\".format( task_slots + needed_sources, needed_sources, task_slots, tm_qty, actual_needed_task_managers_qty ))\n",
    "\n",
    "        list_xp.append(\n",
    "            {\"cpu\": cpu, \n",
    "            \"memory\": memory, \n",
    "            \"run\": 1, \n",
    "            \"task_slots_per_task_manager\": task_slots_per_task_manager, \n",
    "            \"task_managers_qty\": actual_needed_task_managers_qty,\n",
    "            \"source_parallelism\": needed_sources, \n",
    "            \"parallelism\": 1, \n",
    "            \"evenly_spread\": \"true\", \n",
    "            \"warmup\": 120,\n",
    "            \"custom_memory\": None, \n",
    "            \"task_parallelism\": task_parallelism.replace(\"\\\\\\\\\\\\\\\"\", \"\\\\\\\\\\\\\\\"\"),\n",
    "            \"dichotomic_mst_tuning\": None,\n",
    "            \"task_slots_limit\": 0,\n",
    "            \"throughputs\": [int(x * throughput) for x in throughput_ratios],\n",
    "            \"params.TPS\": throughput,\n",
    "            \"timeout\": timeout,\n",
    "            \"params.EVENTS_NUM\": str(int(timeout * throughput * max(throughput_ratios))),\n",
    "            \"params.PERSON_PROPORTION\": \"1\",\n",
    "            \"params.AUCTION_PROPORTION\": \"3\",\n",
    "            \"params.BID_PROPORTION\": \"46\",\n",
    "            \"nb_runs_throughput\": 1,\n",
    "            \"nb_runs_parallelism\": 0,\n",
    "            \"ratio_overhead_throughput\" : ratio_overhead_throughput,\n",
    "            \"sensitivity\": sensitivity,\n",
    "            \"notebook\": notebook})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=Loop_verification\n",
    "import datetime            \n",
    "now = datetime.datetime.now()\n",
    "now_str = now.strftime(\"%Y%m%d%H%M%S\")     \n",
    "path= \"{}/{}-{}\".format(results_path, xp_name, now_str)\n",
    "\n",
    "streambed.loop_verification(list_xp, datagen_configuration, results_path=path, detail_metrics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
